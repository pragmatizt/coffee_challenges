{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPpGiVH2dBVAuG0Zt/pSKA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragmatizt/coffee_challenges/blob/master/pyspark_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FHu8lCoZGG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Walkthrough from: https://towardsdatascience.com/pyspark-in-google-colab-6821c2faf41c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD_FAhzKLoER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the dependencies\n",
        "# If the URL is not found, there may be a newer version of Spark.  Visit these websites for updates:\n",
        "# 1. https://www-us.apache.org/dist/spark/ or 2. http://apache.osuosl.org/spark/\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB0lMg0yLvjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set the environment path that enables us to run PySpark in our Colab environment\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPZkux9ALvsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can run a local spark session to test our installation:\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAEtp2eyOHAG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e715e353-a971-445a-eb20-3e1f3c401f01"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BostonHousing.txt\t\t     spark-2.4.4-bin-hadoop2.7.tgz\n",
            "NOAA_DHW_monthly_798a_0f03_e546.csv  spark-2.4.4-bin-hadoop2.7.tgz.1\n",
            "sample_data\t\t\t     spark-2.4.4-bin-hadoop2.7.tgz.2\n",
            "spark-2.4.4-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj2LIF81OG7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# improt vector assembler, and linear regression modules\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "dataset = spark.read.csv('Boston.csv', inferSchema=True, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPrTfxF5ZTtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "3c4cb61b-a551-417b-a08e-a74b6b05c777"
      },
      "source": [
        "dataset.printSchema()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- crim: double (nullable = true)\n",
            " |-- zn: double (nullable = true)\n",
            " |-- indus: double (nullable = true)\n",
            " |-- chas: integer (nullable = true)\n",
            " |-- nox: double (nullable = true)\n",
            " |-- rm: double (nullable = true)\n",
            " |-- age: double (nullable = true)\n",
            " |-- dis: double (nullable = true)\n",
            " |-- rad: integer (nullable = true)\n",
            " |-- tax: integer (nullable = true)\n",
            " |-- ptratio: double (nullable = true)\n",
            " |-- black: double (nullable = true)\n",
            " |-- lstat: double (nullable = true)\n",
            " |-- medv: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tedMqgOyZplz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "34f720d3-c015-4b66-db4c-f77248cda758"
      },
      "source": [
        "\"\"\"In the next step, we will convert all the features from different columns into a single column and we can \n",
        "call the new vector column as ‘Attributes’ in the outputCol.\"\"\"\n",
        "\n",
        "# Input all the features in one vector column \n",
        "assembler = VectorAssembler(inputCols=['_c0', 'crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat'], outputCol = 'Attributes')\n",
        "\n",
        "output = assembler.transform(dataset)\n",
        "\n",
        "#Input vs Output\n",
        "finalized_data = output.select(\"Attributes\", \"medv\")\n",
        "\n",
        "finalized_data.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+\n",
            "|          Attributes|medv|\n",
            "+--------------------+----+\n",
            "|[1.0,0.00632,18.0...|24.0|\n",
            "|[2.0,0.02731,0.0,...|21.6|\n",
            "|[3.0,0.02729,0.0,...|34.7|\n",
            "|[4.0,0.03237,0.0,...|33.4|\n",
            "|[5.0,0.06905,0.0,...|36.2|\n",
            "|[6.0,0.02985,0.0,...|28.7|\n",
            "|[7.0,0.08829,12.5...|22.9|\n",
            "|[8.0,0.14455,12.5...|27.1|\n",
            "|[9.0,0.21124,12.5...|16.5|\n",
            "|[10.0,0.17004,12....|18.9|\n",
            "|[11.0,0.22489,12....|15.0|\n",
            "|[12.0,0.11747,12....|18.9|\n",
            "|[13.0,0.09378,12....|21.7|\n",
            "|[14.0,0.62976,0.0...|20.4|\n",
            "|[15.0,0.63796,0.0...|18.2|\n",
            "|[16.0,0.62739,0.0...|19.9|\n",
            "|[17.0,1.05393,0.0...|23.1|\n",
            "|[18.0,0.7842,0.0,...|17.5|\n",
            "|[19.0,0.80271,0.0...|20.2|\n",
            "|[20.0,0.7258,0.0,...|18.2|\n",
            "+--------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-NZN4WIalBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "edd1f641-b3fd-4ca4-ddde-e51f390f10c2"
      },
      "source": [
        "# Split training and testing data\n",
        "train_data, test_data = finalized_data.randomSplit([0.8,0.2])\n",
        "\n",
        "regressor = LinearRegression(featuresCol = 'Attributes', labelCol = 'medv')\n",
        "\n",
        "# Learn to fit the model from training set\n",
        "regressor = regressor.fit(train_data)\n",
        "\n",
        "# To predict the prices on testing set\n",
        "pred = regressor.evaluate(test_data)\n",
        "\n",
        "# Predict the model\n",
        "pred.predictions.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+----+------------------+\n",
            "|          Attributes|medv|        prediction|\n",
            "+--------------------+----+------------------+\n",
            "|[2.0,0.02731,0.0,...|21.6| 25.29340301892609|\n",
            "|[4.0,0.03237,0.0,...|33.4| 29.07886236456516|\n",
            "|[5.0,0.06905,0.0,...|36.2|28.453741226694568|\n",
            "|[10.0,0.17004,12....|18.9|19.530596067147894|\n",
            "|[16.0,0.62739,0.0...|19.9|19.711170071069503|\n",
            "|[27.0,0.67191,0.0...|16.6|15.859601134608646|\n",
            "|[30.0,1.00245,0.0...|21.0|21.310434744518787|\n",
            "|[38.0,0.08014,0.0...|21.0| 23.67976435438619|\n",
            "|[41.0,0.03359,75....|34.9| 35.55073385338167|\n",
            "|[45.0,0.12269,0.0...|21.2|23.315585277205805|\n",
            "|[46.0,0.17142,0.0...|19.3|22.485233017671664|\n",
            "|[50.0,0.21977,0.0...|19.4|17.551525295732862|\n",
            "|[51.0,0.08873,21....|19.7|21.964960377318064|\n",
            "|[52.0,0.04337,21....|20.5|24.453709008906475|\n",
            "|[57.0,0.02055,85....|24.7|25.811311208576555|\n",
            "|[59.0,0.15445,25....|23.3|  22.7070051225814|\n",
            "|[62.0,0.17171,25....|16.0|19.339275287767002|\n",
            "|[67.0,0.04379,80....|19.4|26.661064702485323|\n",
            "|[79.0,0.05646,0.0...|21.2| 21.42626077315379|\n",
            "|[82.0,0.04462,25....|23.9|27.412572991199845|\n",
            "+--------------------+----+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdEJp-TOc9eI",
        "colab_type": "text"
      },
      "source": [
        "Next, we print the coefficient and intercept of the regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THTIFuWDc6Ze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "2e248be5-af1e-4c6a-e479-6b60290e9586"
      },
      "source": [
        "# coefficient of the regression model\n",
        "coeff = regressor.coefficients\n",
        "\n",
        "# X and y intercept\n",
        "intr = regressor.intercept\n",
        "\n",
        "print(\"The coefficient of the model is : %a\" %coeff)\n",
        "print(\"The intercept of the model is : %f\" %intr)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The coefficient of the model is : DenseVector([-0.0034, -0.1396, 0.0585, 0.0103, 2.3055, -17.0501, 3.9441, -0.005, -1.5186, 0.3939, -0.014, -0.9339, 0.0079, -0.4938])\n",
            "The intercept of the model is : 36.471211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkMgRp3udPhJ",
        "colab_type": "text"
      },
      "source": [
        "Now we can go further and analyze our model statistically by importing RegressionEvaluator module from Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05FUbfZUdMw6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cd865305-59e8-4bf5-d2bb-3b1c7a14be76"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "eval = RegressionEvaluator(labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Root Mean Square Error\n",
        "rmse = eval.evaluate(pred.predictions)\n",
        "print(\"RMSE: %.3f\" % rmse)\n",
        "\n",
        "# Mean Square Error\n",
        "mse = eval.evaluate(pred.predictions, {eval.metricName: \"mse\"})\n",
        "print(\"MSE: %.3f\" % mse)\n",
        "\n",
        "# Mean Absolute Error\n",
        "mae = eval.evaluate(pred.predictions, {eval.metricName: \"mae\"})\n",
        "print(\"MAE: %.3f\" % mae)\n",
        "\n",
        "# r2 - coefficient of determination\n",
        "r2 = eval.evaluate(pred.predictions, {eval.metricName: \"r2\"})\n",
        "print(\"r2: %.3f\" %r2)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 4.915\n",
            "MSE: 24.162\n",
            "MAE: 3.434\n",
            "r2: 0.689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oApCnvF6d-MV",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}